from openai import OpenAI
from dotenv import load_dotenv
import os
from typing_extensions import override
from openai import AssistantEventHandler
from constants import GRANT_PROPOSAL_WRITE_PROMPT
from fpdf import FPDF


def save_response_as_pdf(text:str, filename="response.pdf"):
    def replace_special_characters(text):
      replacements = {
          '\u2019': "'",
          '\u2018': "'",
          '\u201C': '"',
          '\u201D': '"',
          '\u2013': '-',
          '\u2014': '--',
          # Add more replacements as needed
      }
      for key, value in replacements.items():
          text = text.replace(key, value)
      return text
    
    text = replace_special_characters(text)

    pdf = FPDF()
    pdf.add_page()
    # pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Arial", size = 15)

    pdf.multi_cell(0, 10, text)
    pdf.output(filename)

save_response_as_pdf("Tesetjoeaiwrjaopfijaw")

"""The Event Handler to handle the events in the response stream."""
class EventHandler(AssistantEventHandler):
  # response_text is str that takes the Text value   
  response_text = "" 
  @override
  def on_text_created(self, text) -> None:
    """
    Triggered when a new text 
    is created by assistant
    """
    print(f"\nassistant > ", end="", flush=True)
    # response_text is str that takes the Text value
    # self.response_text = text.value
      
  @override
  def on_text_delta(self, delta, snapshot):
    """
    Triggered when a delta change in the 
    text being generated by assistant. 
    Used to provide a streaming effect. 
    """
    print(delta.value, end="", flush=True)
    self.response_text += delta.value
      
  def on_tool_call_created(self, tool_call):
    """
    Triggered when a tool call is created 
    It prints out the tool used 
    """
    print(f"\nassistant > {tool_call.type}\n", flush=True)
  
  @override
  def on_text_done(self, text):
    #  print(f"\nThis is triggered {self.response_text[:30]}")
     save_response_as_pdf(self.response_text)
     print("\nResponse saved as response.pdf")
  
  # def on_tool_call_delta(self, delta, snapshot):
  #   if delta.type == 'code_interpreter':
  #     if delta.code_interpreter.input:
  #       print(delta.code_interpreter.input, end="", flush=True)
  #     if delta.code_interpreter.outputs:
  #       print(f"\n\noutput >", flush=True)
  #       for output in delta.code_interpreter.outputs:
  #         if output.type == "logs":
  #           print(f"\n{output.logs}", flush=True)



load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


assistant = client.beta.assistants.create(
  name="Research Assistant",
  instructions=GRANT_PROPOSAL_WRITE_PROMPT,
  tools=[{"type": "file_search"}],
  model="gpt-4o",
)

thread = client.beta.threads.create()





def write_proposal_given_idea(text:str):
    message = client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=text
    )
    # Then, we use the `stream` SDK helper 
    # with the `EventHandler` class to create the Run 
    # and stream the response.
    with client.beta.threads.runs.stream(
      thread_id=thread.id,
      assistant_id=assistant.id,
      instructions="Do not state extra greeting beginning statments",
      event_handler=EventHandler(),
    ) as stream:
      stream.until_done()


TEST_QUESTION = """
I have a project idea of bridging the digital divide by providing 
technology education and resoruce to underpriviledged students. 
Please write me a grant proposal template that should work for 
a decent amount of general grant-provider organizations.
"""
write_proposal_given_idea(TEST_QUESTION)

 

 

 
